{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cuda_on_colab.ipynb","provenance":[],"authorship_tag":"ABX9TyPqBnG1jPElk3ZGkDTugaKJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install Prerequisites"],"metadata":{"id":"tT4786xJBWKD"}},{"cell_type":"markdown","source":["### Remove existing CUDA installation and NVIDIA drivers (optional)"],"metadata":{"id":"phO2W5bZqdHt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQtstBaofzYT"},"outputs":[],"source":["# !apt-get --purge remove cuda nvidia* libnvidia-*\n","# !dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n","# !apt-get remove cuda-*\n","# !apt autoremove\n","# !apt-get update"]},{"cell_type":"markdown","source":["### Install specific CUDA (optional)"],"metadata":{"id":"6t2vFrA3qlE5"}},{"cell_type":"code","source":["# !wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n","# !dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n","# !apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n","# !apt-get update\n","# !apt-get install cuda-9.2"],"metadata":{"id":"Othydrgyf-qF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Installation check"],"metadata":{"id":"8SnWeOi9qrNU"}},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZA1C6v_JhI0E","executionInfo":{"status":"ok","timestamp":1644467188547,"user_tz":-330,"elapsed":11,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"ecce2706-ba6f-4267-aaad-40f7c5f6636a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"markdown","source":["Install a jupyter extension"],"metadata":{"id":"SzaCN9poqvf0"}},{"cell_type":"code","source":["!pip install git+git://github.com/j143/nvcc4jupyter.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2LjqG42cgdQQ","executionInfo":{"status":"ok","timestamp":1644467207538,"user_tz":-330,"elapsed":4599,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"b4e3cdb0-b681-4d3a-8d5b-fcd9484688c3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+git://github.com/j143/nvcc4jupyter.git\n","  Cloning git://github.com/j143/nvcc4jupyter.git to /tmp/pip-req-build-bmsddg1m\n","  Running command git clone -q git://github.com/j143/nvcc4jupyter.git /tmp/pip-req-build-bmsddg1m\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=8e5c1d33f097359faac19a33ddab1dc8b0c99dcd1957490a2c6652f8b0a6e62a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-40gt56am/wheels/26/f6/b6/abe58d118498a098d0c925b2011902a9f1b4a50629ef215768\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n"]}]},{"cell_type":"markdown","source":["Load the plugin"],"metadata":{"id":"tabn9_zlqyx3"}},{"cell_type":"code","source":["%load_ext nvcc_plugin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uVGJjHrhdOu","executionInfo":{"status":"ok","timestamp":1644467213821,"user_tz":-330,"elapsed":5,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"006b7f57-c77f-4c0a-e657-05989573927f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["created output directory at /content/src\n","Out bin /content/result.out\n"]}]},{"cell_type":"markdown","source":["# Run CUDA"],"metadata":{"id":"lgumuFZuBsw2"}},{"cell_type":"markdown","source":["### Run a print example"],"metadata":{"id":"v0COdZH9q0lV"}},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","\n","int main() {\n","    std::cout << \"This is from CUDA\\n\";\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfhvU2Ghhh_U","executionInfo":{"status":"ok","timestamp":1644467222156,"user_tz":-330,"elapsed":2576,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"44ac3a0a-2379-4273-9cef-71eacc163683"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["This is from CUDA\n","\n"]}]},{"cell_type":"markdown","source":["### Involved example"],"metadata":{"id":"rkbs-IDaB14q"}},{"cell_type":"code","source":["int('0b100', base=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeiisHlji1-8","executionInfo":{"status":"ok","timestamp":1644467228225,"user_tz":-330,"elapsed":641,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"8a1d8c07-bcb6-46ad-8c76-f3c6b03b33ea"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["%%cu\n","#include <cstdio>\n","#include <iostream>\n","\n","using namespace std;\n","\n","__global__ void maxi(int* a, int* b, int n) {\n","\tint block = 256 * blockIdx.x;\n","\tint max = 0;\n","\n","\tfor (int i = block; i < min(256 + block, n); i++) {\n","\t\tif (max < a[i]) {\n","\t\t\tmax = a[i];\n","\t\t}\n","\t}\n","\tb[blockIdx.x] = max;\n","}\n","\n","int main() {\n","\n","\tint n;\n","\tn = 3 >> 2;\n","\tint a[n];\n","\n","\tfor (int i = 0; i < n; i++) {\n","\t\ta[i] = rand() % n;\n","\t\tcout << a[i] << \"\\t\";\n","\t}\n","\n","\tcudaEvent_t start, end;\n","\tint *ad, *bd;\n","\tint size = n * sizeof(int);\n","\tcudaMalloc(&ad, size);\n","\tcudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n","\tint grids = ceil(n * 1.0f / 256.0f);\n","\tcudaMalloc(&bd, grids * sizeof(int));\n","\n","\tdim3 grid(grids, 1);\n","\tdim3 block(1, 1);\n","\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&end);\n","\tcudaEventRecord(start);\n","\n","\twhile (n > 1) {\n","\t\tmaxi<<<grids, block>>>(ad, bd, n);\n","\t\tn = ceil(n * 1.0f / 256.0f);\n","\t\tcudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n","\t}\n","\n","\tcudaEventRecord(end);\n","\tcudaEventSynchronize(end);\n","\n","\tfloat time = 0;\n","\tcudaEventElapsedTime(&time, start, end);\n","\n","\tint ans[2];\n","\tcudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n","\n","\tcout << \"The maximum element is : \" << ans[0] << endl;\n","\n","\tcout << \"The time required : \";\n","\tcout << time << endl;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTOfhmfwh3s4","executionInfo":{"status":"ok","timestamp":1644467247461,"user_tz":-330,"elapsed":2069,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"ec1de3f9-67e9-45b1-be56-536e30af3a90"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["The maximum element is : -1365408560\n","The time required : 0.003264\n","\n"]}]},{"cell_type":"markdown","source":["### Example 1"],"metadata":{"id":"7NKE8Zd8kH3R"}},{"cell_type":"code","source":["%%cu\n","\n","#include <stdio.h>\n","\n","// This is a special function that runs on the GPU (device) instead of the CPU (host)\n","__global__ void kernel() {\n","  printf(\"Hello world!\\n\");\n","}\n","\n","int main() {\n","  // Invoke the kernel function on the GPU with one block of one thread\n","  kernel<<<1,1>>>();\n","\n","  // Check for error codes (remember to do this for _every_ CUDA function)\n","  if(cudaDeviceSynchronize() != cudaSuccess) {\n","    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(cudaPeekAtLastError()));\n","  }\n","\n","  return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoRsWBb-kHWn","executionInfo":{"status":"ok","timestamp":1644467307649,"user_tz":-330,"elapsed":1034,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"1fa37663-53fd-48f7-c5e9-4a1e1edc0aed"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello world!\n","\n"]}]},{"cell_type":"markdown","source":["### Example 2"],"metadata":{"id":"dZHP7I8yB_Xt"}},{"cell_type":"code","source":["%%cu\n","\n","#include <stdio.h>\n","\n","// This kernel runs on the GPU and prints the thread's identifiers\n","__global__ void kernel() {\n","  printf(\"Hello from block %d thread %d\\n\", blockIdx.x, threadIdx.x);\n","}\n","\n","int main() {\n","  // Launch the kernel on the GPU with four blocks of six threads each\n","  kernel<<<4,2>>>();\n","\n","  // Check for CUDA errors\n","  if(cudaDeviceSynchronize() != cudaSuccess) {\n","    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(cudaPeekAtLastError()));\n","  }\n","  return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKhIVZ2Ckdyb","executionInfo":{"status":"ok","timestamp":1644467511421,"user_tz":-330,"elapsed":1289,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"8303e2a8-087a-4d2b-a163-06c829aebf93"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello from block 2 thread 0\n","Hello from block 2 thread 1\n","Hello from block 0 thread 0\n","Hello from block 0 thread 1\n","Hello from block 3 thread 0\n","Hello from block 3 thread 1\n","Hello from block 1 thread 0\n","Hello from block 1 thread 1\n","\n"]}]},{"cell_type":"markdown","source":["### Example 3"],"metadata":{"id":"gDACDMfTCDs5"}},{"cell_type":"code","source":["%%cu\n","\n","#include <stdint.h>\n","#include <stdio.h>\n","\n","#define N 32\n","#define THREADS_PER_BLOCK 32\n","\n","__global__ void saxpy(float a, float* x, float* y) {\n","  // Which index of the array should this thread use?\n","  size_t index = 20;\n","\n","  // Compute a times x plus y for a specific index\n","  y[index] = a * x[index] + y[index];Z\n","}\n","\n","int main() {\n","  // Allocate arrays for X and Y on the CPU. This memory is only usable on the CPU\n","  float* cpu_x = (float*)malloc(sizeof(float) * N);\n","  float* cpu_y = (float*)malloc(sizeof(float) * N);\n","\n","  // Initialize X and Y\n","  int i;\n","  for(i=0; i<N; i++) {\n","    cpu_x[i] = (float)i;\n","    cpu_y[i] = 0.0;\n","  }\n","\n","  // The gpu_x and gpu_y pointers will only be usable on the GPU (which uses separate memory)\n","  float* gpu_x;\n","  float* gpu_y;\n","\n","  // Allocate space for the x array on the GPU\n","  if(cudaMalloc(&gpu_x, sizeof(float) * N) != cudaSuccess) {\n","    fprintf(stderr, \"Failed to allocate X array on GPU\\n\");\n","    exit(2);\n","  }\n","\n","  // Allocate space for the y array on the GPU\n","  if(cudaMalloc(&gpu_y, sizeof(float) * N) != cudaSuccess) {\n","    fprintf(stderr, \"Failed to allocate Y array on GPU\\n\");\n","    exit(2);\n","  }\n","\n","  // Copy the cpu's x array to the gpu with cudaMemcpy\n","  if(cudaMemcpy(gpu_x, cpu_x, sizeof(float) * N, cudaMemcpyHostToDevice) != cudaSuccess) {\n","    fprintf(stderr, \"Failed to copy X to the GPU\\n\");\n","  }\n","\n","  // Copy the cpu's y array to the gpu with cudaMemcpy\n","  if(cudaMemcpy(gpu_y, cpu_y, sizeof(float) * N, cudaMemcpyHostToDevice) != cudaSuccess) {\n","    fprintf(stderr, \"Failed to copy Y to the GPU\\n\");\n","  }\n","\n","  // Calculate the number of blocks to run, rounding up to include all threads\n","  size_t blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n","\n","  // Run the saxpy kernel\n","  saxpy<<<blocks, THREADS_PER_BLOCK>>>(0.5, gpu_x, gpu_y);\n","\n","  // Wait for the kernel to finish\n","  if(cudaDeviceSynchronize() != cudaSuccess) {\n","    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(cudaPeekAtLastError()));\n","  }\n","\n","  // Copy the y array back from the gpu to the cpu\n","  if(cudaMemcpy(cpu_y, gpu_y, sizeof(float) * N, cudaMemcpyDeviceToHost) != cudaSuccess) {\n","    fprintf(stderr, \"Failed to copy Y from the GPU\\n\");\n","  }\n","\n","  // Print the updated y array\n","  for(i=0; i<N; i++) {\n","    printf(\"%d: %f\\n\", i, cpu_y[i]);\n","  }\n","\n","  cudaFree(gpu_x);\n","  cudaFree(gpu_y);\n","  free(cpu_x);\n","  free(cpu_y);\n","\n","  return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKAZmeMekgWp","executionInfo":{"status":"ok","timestamp":1644467556945,"user_tz":-330,"elapsed":403,"user":{"displayName":"Janardhan Pulivarthi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTO9NL5UN4X2mJBWVGmcVDKIA7dPkwvmUn340unA=s64","userId":"01462266390931072836"}},"outputId":"601aa6e2-d9cf-4dc1-f352-529c8bf2c8e5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["/tmp/tmpzza2hszf/5bd0fb96-f0fd-4537-a788-0ddff5743a19.cu(13): error: identifier \"Z\" is undefined\n","\n","/tmp/tmpzza2hszf/5bd0fb96-f0fd-4537-a788-0ddff5743a19.cu(14): error: expected a \";\"\n","\n","2 errors detected in the compilation of \"/tmp/tmpzza2hszf/5bd0fb96-f0fd-4537-a788-0ddff5743a19.cu\".\n","\n"]}]}]}
